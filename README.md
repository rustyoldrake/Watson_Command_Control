# Watson_Command_Control
VOICE Command and Control of On-screen artifacts and AR / VR Images ( sort of like "Jarvis" from Iron Man)

https://www.youtube.com/watch?v=36Hhb1RdbKU

COMMAND AND CONTROL - PART 1 - 

Quick demo of Graphics and Speech Modules for Verbal Manipulation (and Invoking) of Virtual Objects / Artifacts using 
IBM Watson Speech to Text and NLC Services from Watson Developer Cloud.

Longer term - as part of some #STEM work with my kids - we are building out some "Jarvis Like" interfaces for our home-built AR glasses in the lab - so this is the first step in creating and manipulating Virtual Objects in the field of view.

TO COME:
- Jarvis/MacKenzie talks back and engages user
- Ability to "invoke" more ideas and images on the fly
- Using NLC for more sophisticated understanding of user utterance (intent)

Thanks to my awesome kids for the help building out the UX and the "Pixel Art"

https://github.com/rustyoldrake
https://github.com/rustyoldrake/Watson_Command_Control
